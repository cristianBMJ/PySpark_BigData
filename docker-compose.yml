# V2
version: '3'

services:
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck: # check functioning c
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

  airflow-init:
    build:
        context: .
        dockerfile: Dockerfile
    # image: cristianmb/big_data_yfinance_demo:1.0 
    container_name: airflow-init
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/config/commodities-with-looker-ebea952a6145.json

    volumes:
      - ./config/airflow.cfg:/app/airflow/airflow.cfg:ro
      - ./config/service-account-key.json:/app/config/service-account-key.json:ro
    command: >
      bash -c "
        airflow db init &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin &&
        echo 'Initialization complete.'"

  airflow-webserver:
    build:
        context: .
        dockerfile: Dockerfile
    # image: cristianmb/big_data_yfinance_demo:1.0   
    container_name: airflow-webserver
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    ports:
      - "8081:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/config/commodities-with-looker-ebea952a6145.json

    volumes:
      - ./airflow/dags:/app/airflow/dags
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./config/airflow.cfg:/app/airflow/airflow.cfg:ro
      - ./config/service-account-key.json:/app/config/service-account-key.json:ro
    command: airflow webserver

  airflow-scheduler:
    build:
        context: .
        dockerfile: Dockerfile
    # image: cristianmb/big_data_yfinance_demo:1.0   
    container_name: airflow-scheduler
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY}
      - GOOGLE_APPLICATION_CREDENTIALS=/app/config/commodities-with-looker-ebea952a6145.json

    volumes:
      - ./airflow/dags:/app/airflow/dags
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./config/airflow.cfg:/app/airflow/airflow.cfg:ro
      - ./config/service-account-key.json:/app/config/service-account-key.json:ro
    command: airflow scheduler

  spark:
    image: bitnami/spark:latest
    container_name: spark
    environment:
      - SPARK_MODE=master
      #- JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64  # Optional, as it's already set in Dockerfile
      - SPARK_DRIVER_MEMORY=2g      
    ports:
      - "8080:8080"
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data

volumes:
  postgres_data:
